{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8391a65-56d1-48a4-896f-3656d3c86eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1b2361-6473-415e-acc9-ed0ad55f662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Jun 04, 2025 2:07:50 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
      "WARNING: No Unicode mapping for .notdef (10) in font ABCDEE+Calibri\n",
      "Jun 04, 2025 2:07:54 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
      "WARNING: No Unicode mapping for .notdef (10) in font ABCDEE+Calibri\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
      "WARNING: Building on-disk font cache, this may take a while\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
      "WARNING: Finished building on-disk font cache, found 0 fonts\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'ArialMT'\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'Arial-BoldMT'\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'ArialMT'\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'Arial-BoldMT'\n",
      "Jun 04, 2025 2:07:57 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
      "Jun 04, 2025 2:07:59 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPS-BoldMT'\n",
      "Jun 04, 2025 2:07:59 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'ArialMT'\n",
      "Jun 04, 2025 2:07:59 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'Arial-BoldMT'\n",
      "Jun 04, 2025 2:08:01 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'ArialMT'\n",
      "Jun 04, 2025 2:08:01 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
      "Jun 04, 2025 2:08:01 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
      "\n",
      "/home/users/kieran/miniconda3/envs/py311/lib/python3.11/site-packages/tabula/io.py:1054: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
      "/home/users/kieran/miniconda3/envs/py311/lib/python3.11/site-packages/tabula/io.py:1054: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
      "/home/users/kieran/miniconda3/envs/py311/lib/python3.11/site-packages/tabula/io.py:1054: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
      "/home/users/kieran/miniconda3/envs/py311/lib/python3.11/site-packages/tabula/io.py:1054: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
      "/home/users/kieran/miniconda3/envs/py311/lib/python3.11/site-packages/tabula/io.py:1054: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "tables = tabula.read_pdf(\"../../cea-data/installed-capacity-raw.pdf\", pages='all', multiple_tables=True, lattice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ab66d6-f751-4756-9aab-0ecbc5d4a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n"
     ]
    }
   ],
   "source": [
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804c80e-6a22-44e7-85c2-6516be23ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,df in enumerate(tables):\n",
    "\tdf.to_csv(\"../../cea-data/cea-table-dump/{:04d}.csv\".format(n), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba8ea2-a7aa-4089-b856-4b5ccf554115",
   "metadata": {},
   "source": [
    "# Parse tables and extract location data using Bing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d89fe16-0235-4b1d-a412-a5240343ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateparser\n",
    "from glob import glob\n",
    "import re\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim, Bing\n",
    "import geopy\n",
    "import geopandas\n",
    "from shapely.geometry import Point, Polygon\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a964346a-d0d9-4d7e-9914-6f19554aad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Bing geolocator to parse random addresses\n",
    "\n",
    "geopy.geocoders.options.default_timeout = None\n",
    "\n",
    "bing_key = '<insert your API key here>'\n",
    "geolocator = Bing(api_key=bing_key)\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffe832a-970f-458b-a469-4c73b88cd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to find Indian state given a lat/lon point\n",
    "\n",
    "state_shps = geopandas.read_file(\"../other-files/gadm36_IND_1.shp\")\n",
    "\n",
    "def find_state(lon, lat):\n",
    "\tp = Point(lon, lat)\n",
    "\tpnts = geopandas.GeoDataFrame(geometry=[p,],)\n",
    "\tpnts = pnts.assign(**{key: pnts.within(geom) for key, geom in zip(state_shps.NAME_1,state_shps.geometry)})\n",
    "\t\n",
    "\tin_state = pnts.loc[0][1:].values.astype(bool)\n",
    "\tstate_names = pnts.columns[1:].values\n",
    "\t\n",
    "\tif np.sum(in_state):\n",
    "\t\treturn(state_names[in_state][0])\n",
    "\telse:\n",
    "\t\treturn(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b4bc9b-abb8-4da7-9c4e-2eb50ba27390",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_in_df = lambda s, df: np.sum([df[col].str.contains(s, flags = re.IGNORECASE).sum() for col in df])\n",
    "find_col_with_string = lambda s, df: np.where([df[col].str.contains(s, flags = re.IGNORECASE).sum() for col in df])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c727c3dd-9dbb-4de9-b88c-c46ea06c4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlist = sorted(glob(\"../../cea-data/cea-table-dump/*.csv\"))\n",
    "\n",
    "output = {\"lon\":[],\"lat\":[],\"capacity_MW\":[],\"installed\":[], \"district\":[], \"state\":[], \"type\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c586ab-da41-4818-86fe-b45106158097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all tables in the file, then parse out useful info on installed capacity and location\n",
    "\n",
    "for nt,tname in enumerate(tlist):\n",
    "\t\n",
    "\ttcode = int(tname.split(\"/\")[-1].split(\".\")[0])\n",
    "\tif tcode in range(1293,1301): continue #avoid the weird nested tables for part of Maharashtra\n",
    "\t\n",
    "\n",
    "\t#tname = tlist[87]\n",
    "\tprint(nt, tname)\n",
    "\n",
    "\t#skip files that are summary headers\n",
    "\ttextfile = open(tname, 'r')\n",
    "\tfiletext = textfile.read()\n",
    "\ttextfile.close()\n",
    "\tmatches = re.findall(\"summary of RE\", filetext, re.IGNORECASE)\n",
    "\tif matches: continue\n",
    "\n",
    "\ttry:\n",
    "\t\tdf = pd.read_csv(tname, lineterminator=\"\\n\").dropna(how='all').dropna(thresh=4)\n",
    "\texcept pd.errors.EmptyDataError:\n",
    "\t\tcontinue #skip blank files\n",
    "\t\n",
    "\t\n",
    "\tdf = df.replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\r',  ' ', regex=True)\n",
    "\t\n",
    "\t\n",
    "\tprint(df)\t\n",
    "\n",
    "\t#check for and remove summary row, if present\n",
    "\tif df.iloc[-1].str.contains('[Tt]otal', flags = re.IGNORECASE, na=False).any():\n",
    "\t\tdf = df[:-1]\n",
    "\t\n",
    "\t\n",
    "\n",
    "\t#first check the whole table for clues about the energy source\n",
    "\n",
    "\ttry:\n",
    "\t\tif string_in_df('[Ww]ind', df):\n",
    "\t\t\tsource = \"Wind\"\n",
    "\t\telif string_in_df('[Ss]olar', df):\n",
    "\t\t\tsource = \"Solar\"\n",
    "\t\telif string_in_df('[Hh]ydro', df):\n",
    "\t\t\tsource = \"Hydro\"\n",
    "\t\telif string_in_df('[Bb]io[\\s\\S]?[Mm]ass', df):\n",
    "\t\t\tsource = \"Biomass\"\n",
    "\t\telse:\n",
    "\t\t\tsource = \"other\"\n",
    "\n",
    "\texcept:continue #this only fails on the horribly messy nested Maharashtra tables, so skip those\n",
    "\t\n",
    "\n",
    "\tprint(source)\n",
    "\n",
    "\t#use the fact that all tables contain some capacity info to figure out the structure of table\n",
    "\tiy = find_col_with_string('capacity', df)\n",
    "\tcap_col = df.iloc[:,iy]\n",
    "\tstart_index = np.where(cap_col.str.contains('capacity', flags = re.IGNORECASE, na=False))[0][-1]\n",
    "\t#print(cap_col)\n",
    "\t#print(start_index)\n",
    "\n",
    "\t\n",
    "\n",
    "\tnew_header = df.iloc[start_index] \n",
    "\t\n",
    "\t\n",
    "\tdf = df[start_index+1:] \n",
    "\tdf.columns = [str(h).lower() for h in new_header]\n",
    "\t\n",
    "\t#manual fix to sort botched tables in some Karnatka data\n",
    "\tif tname in [\"../../cea-data/cea-table-dump/{:04d}.csv\".format(R) for R in range(98,191)]:\t\n",
    "\t\tdf.columns = np.roll(df.columns,-1)\n",
    "\n",
    "\t\n",
    "\tprint(df)\n",
    "\n",
    "\n",
    "\t#extract and convert useful data\n",
    "\n",
    "\tcap_raw = np.ravel(df.filter(like='capacity').values)\n",
    "\tcapacities = []\n",
    "\tfor c in cap_raw:\n",
    "\t\tif type(c)==str:\n",
    "\t\t\tc = re.sub(r'[^0-9\\.]', '', c)\n",
    "\t\t\tif c:\n",
    "\t\t\t\tif c[0] ==\".\":\n",
    "\t\t\t\t\tc = c[1:]\n",
    "\t\t\telse:\n",
    "\t\t\t\tcapacities.append(np.nan)\n",
    "\t\t\t\tcontinue\n",
    "\t\tcapacities.append(float(c))\n",
    "\t\t\t\n",
    "\t\n",
    "\n",
    "\tdate_raw = np.ravel(df.filter(like='date').values)\n",
    "\tdates = [dateparser.parse(d) if type(d)==str else np.nan for d in date_raw]\n",
    "\n",
    "\tif \"state\" in df.columns:\n",
    "\t\tstates = np.ravel(df.filter(like='state').values)\n",
    "\telse:\n",
    "\t\tstates = np.zeros_like(dates)\n",
    "\t\tstates[:]=\"\"\n",
    "\n",
    "\n",
    "\tlocations = np.ravel(df.filter(like='location').values)\n",
    "\t\n",
    "\t#filter out remaining nans\n",
    "\tlocations = [L.split(\"-\")[0] if type(L)==str else \"\" for L in locations]\n",
    "\tstates = [S if type(S)==str else states[0] for S in states]\n",
    "\n",
    "\tlstrings = [a.replace(\"\\\"\",\"\").replace(\"dist\",\"\").replace(\"Dist\",\"\").strip()+\", \"+b+\", India\" for a,b in zip(locations,states)]\n",
    "\tprint(lstrings)\n",
    "\n",
    "\n",
    "\t\n",
    "\t\n",
    "\tfor lstring in lstrings:\n",
    "\t\tlocation = geocode(lstring)\n",
    "\t\tif location is not None:\n",
    "\t\t\tlon = location.longitude\n",
    "\t\t\tlat = location.latitude\n",
    "\t\t\tstate = find_state(lon,lat)\n",
    "\t\t\tprint(lon, lat, state)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tlon = np.nan\n",
    "\t\t\tlat = np.nan\n",
    "\t\t\tstate = states[0]\n",
    "\t\t\n",
    "\t\toutput['lon'].append(lon)\n",
    "\t\toutput['lat'].append(lat)\n",
    "\t\toutput['state'].append(state)\n",
    "\t\n",
    "\n",
    "\ttypes = [source,]*len(capacities)\n",
    "\t\n",
    "\toutput['type'].extend(types)\n",
    "\toutput['capacity_MW'].extend(capacities)\n",
    "\toutput['installed'].extend(dates)\n",
    "\toutput['district'].extend(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33be9cc-5ed6-4607-8d39-452485433c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(output)\n",
    "df.to_csv(\"../../cea-data/parsed-cea-all.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py311)",
   "language": "python",
   "name": "py311-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
